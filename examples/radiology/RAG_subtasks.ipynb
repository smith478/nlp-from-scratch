{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36a9e4bd",
   "metadata": {},
   "source": [
    "Prior to running this notebook run: `ollama serve &`. This will start the Ollama server and allow you to interact with it through this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13201b23-bfbf-448e-9598-f1fd42ef35ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/nlp-from-scratch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from typing import List, Dict, Union\n",
    "\n",
    "from utils import json_to_dataframe, json_to_string_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "519c3c5a-fdfa-400f-b11f-6c1c4fddcd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '../../data/vector_veterinary_imaging_2.json'\n",
    "\n",
    "df = json_to_dataframe(filepath) \n",
    "rad_strings = json_to_string_list(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c52b6f5e-9982-45e2-b7e3-b1363bd4c4da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_identifier</th>\n",
       "      <th>findings</th>\n",
       "      <th>conclusions_and_recommendations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>181153</td>\n",
       "      <td>Orthogonal pelvis and orthogonal right shoulde...</td>\n",
       "      <td>1. Medial right mildly comminuted acetabular f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181413</td>\n",
       "      <td>Three view whole body images dated April 14, 2...</td>\n",
       "      <td>The material within the stomach and small inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>181821</td>\n",
       "      <td>Three view thoracic radiographs (total of 5 th...</td>\n",
       "      <td>No aggressive osseous changes are noted. The b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>181886</td>\n",
       "      <td>Orthogonal images of the right pelvic limb are...</td>\n",
       "      <td>1. Chronic right calcaneal tendonopathy, with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>181911</td>\n",
       "      <td>Lateral abdomen and pelvis images are provided...</td>\n",
       "      <td>1. Numerous small urinary cystoliths, non-obst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>274208</td>\n",
       "      <td>Three view thorax and three view abdomen image...</td>\n",
       "      <td>Aggressive osseous change of the L6 vertebral ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>274229</td>\n",
       "      <td>Orthogonal thorax and three view abdomen image...</td>\n",
       "      <td>Right cranial pulmonary mass. This is most lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>274244</td>\n",
       "      <td>Liver: Diffusely homogenously hyperechoic, oth...</td>\n",
       "      <td>At least one gastric mural nodule extending in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1759</th>\n",
       "      <td>274249</td>\n",
       "      <td>Ventrodorsal pelvis and orthogonal stifles ima...</td>\n",
       "      <td>Right coxofemoral subluxation, progressive fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760</th>\n",
       "      <td>274264</td>\n",
       "      <td>Lateral left and right thoracic limbs, cranioc...</td>\n",
       "      <td>Normal pelvis and thoracic and pelvic limbs. A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1761 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      case_identifier                                           findings  \\\n",
       "0              181153  Orthogonal pelvis and orthogonal right shoulde...   \n",
       "1              181413  Three view whole body images dated April 14, 2...   \n",
       "2              181821  Three view thoracic radiographs (total of 5 th...   \n",
       "3              181886  Orthogonal images of the right pelvic limb are...   \n",
       "4              181911  Lateral abdomen and pelvis images are provided...   \n",
       "...               ...                                                ...   \n",
       "1756           274208  Three view thorax and three view abdomen image...   \n",
       "1757           274229  Orthogonal thorax and three view abdomen image...   \n",
       "1758           274244  Liver: Diffusely homogenously hyperechoic, oth...   \n",
       "1759           274249  Ventrodorsal pelvis and orthogonal stifles ima...   \n",
       "1760           274264  Lateral left and right thoracic limbs, cranioc...   \n",
       "\n",
       "                        conclusions_and_recommendations  \n",
       "0     1. Medial right mildly comminuted acetabular f...  \n",
       "1     The material within the stomach and small inte...  \n",
       "2     No aggressive osseous changes are noted. The b...  \n",
       "3     1. Chronic right calcaneal tendonopathy, with ...  \n",
       "4     1. Numerous small urinary cystoliths, non-obst...  \n",
       "...                                                 ...  \n",
       "1756  Aggressive osseous change of the L6 vertebral ...  \n",
       "1757  Right cranial pulmonary mass. This is most lik...  \n",
       "1758  At least one gastric mural nodule extending in...  \n",
       "1759  Right coxofemoral subluxation, progressive fro...  \n",
       "1760  Normal pelvis and thoracic and pelvic limbs. A...  \n",
       "\n",
       "[1761 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0330b5ba-dd87-48ad-bc9e-a3cd531df25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "findings = list(df['findings'])\n",
    "conclusions = list(df['conclusions_and_recommendations'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7647ea8f-0fc8-459c-a97f-9808fb2c1fcc",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5171c12d-74f2-4cc5-adf5-ad6627298d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceTransformerRetriever(dspy.Retrieve):\n",
    "    def __init__(self, model: str, findings: List[str], conclusions: List[str], k: int):\n",
    "        self.model = model if isinstance(model, SentenceTransformer) else SentenceTransformer(model, trust_remote_code=True)\n",
    "        self.findings = findings\n",
    "        self.conclusions = conclusions\n",
    "        self.k = k\n",
    "        self.embeddings = None\n",
    "        self.init_embeddings()\n",
    "\n",
    "    def init_embeddings(self):\n",
    "        self.embeddings = self.model.encode(self.findings)\n",
    "\n",
    "    def forward(self, query: str, k: int) -> List[Dict[str, Union[str, float]]]:\n",
    "        query_embedding = self.model.encode([query])\n",
    "        similarities = cosine_similarity(query_embedding, self.embeddings)[0]\n",
    "        top_k_indices = np.argsort(similarities)[-k:][::-1]\n",
    "\n",
    "        results = []\n",
    "        for idx in top_k_indices:\n",
    "            results.append({\n",
    "                'finding': self.findings[idx],\n",
    "                'conclusion': self.conclusions[idx],\n",
    "                'score': float(similarities[idx])\n",
    "            })\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b99c231-1c02-4a25-bd49-0ea166144e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "# vectorizer = \"dunzhang/stella_en_400M_v5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "710d5901-0986-427e-b884-e7c906cd3f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/nlp-from-scratch/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 56/56 [00:09<00:00,  6.15it/s]\n"
     ]
    }
   ],
   "source": [
    "retriever_model = SentenceTransformerRetriever(model=vectorizer, findings=findings, conclusions=conclusions, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76e99355-5d3f-420b-b401-679a33e41651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Three view whole body images dated April 14, 2023 are provided for review. The lungs are well-inflated. The cardiopulmonary structures are normal. No pulmonary nodules or intrathoracic lymphadenopathy are identified. The cardiac silhouette and associated vasculature are normal. The pleural space and diaphragmatic margin are normal. The stomach contains a moderate amount of amorphous granular soft tissue opaque material. The stomach is normal in position. No gastric wall thickening or mass effects are appreciated.the small intestine contains a mild amount of similarly textured soft tissue opaque material mixed with gas and fluid. Two populations of small intestine are not identified. The colon contains a moderate amount of granular formed fecal material. The peritoneal and retroperitoneal serosal detail is adequate. The visible hepatic, splenic, and renal silhouette margins are normal. The urinary bladder is moderately filled. The osseous structures are within normal limits.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findings[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7a33d5c-cca5-4211-93b0-55405fb01539",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'finding': 'Three view whole body images dated April 14, 2023 are provided for review. The lungs are well-inflated. The cardiopulmonary structures are normal. No pulmonary nodules or intrathoracic lymphadenopathy are identified. The cardiac silhouette and associated vasculature are normal. The pleural space and diaphragmatic margin are normal. The stomach contains a moderate amount of amorphous granular soft tissue opaque material. The stomach is normal in position. No gastric wall thickening or mass effects are appreciated.the small intestine contains a mild amount of similarly textured soft tissue opaque material mixed with gas and fluid. Two populations of small intestine are not identified. The colon contains a moderate amount of granular formed fecal material. The peritoneal and retroperitoneal serosal detail is adequate. The visible hepatic, splenic, and renal silhouette margins are normal. The urinary bladder is moderately filled. The osseous structures are within normal limits.',\n",
       "  'conclusion': 'The material within the stomach and small intestine is compatible with ingesta. It is possible that this material is obscuring visualization of gastric or small intestinal wall thickening. No distinct mass effect or mechanical obstruction is identified. Given the description of cranial abdominal discomfort, acute pancreatitis may also be present that is not radiographically evident. Consideration could be given to testing for acute pancreatitis and further evaluation of the stomach and small intestine with a fasted abdominal ultrasound which can better evaluate for altered wall layering and thickness, pancreatic lesions, and subtle lymphadenopathy and steatitis.',\n",
       "  'score': 1.0},\n",
       " {'finding': 'Three view whole body images dated 3/11/2024 are provided for review (total of 3 images). The lungs are well-inflated and normal in appearance. No pulmonary nodules or intrathoracic lymphadenopathy are identified. The cardiac silhouette and pulmonary vasculature are normal in size and margin. The pleural pace and mediastinum are normal. The diaphragmatic margin is normal. No mass effects are noted in the abdomen. On all images, the stomach is largely gas-filled and contains mild amorphous soft tissue opaque material, normal in position. The small intestine is mildly diffusely gas-filled with few loops containing mild amorphous soft tissue opaque material. Two populations of small intestine are not present. No plication is noted. The peritoneal serosal detail is adequate. The colon contains a large amount of gas and moderate volume of poorly defined fecal material. The prostate is mildly enlarged and smooth in margin. The osseous structures are normal.',\n",
       "  'conclusion': 'The large size of the gastric lumen may be due to aerophagia or gastric atony caused by inflammation or much less likely pyloric outflow obstruction to an unseen source. No evidence of gastrotintestinal foreign material is identified. A cause for vomiting and diarrhea is not apparent, and may be due to inflammatory/immune-mediated causes, acute pancreatitis, infectious causes (viral, bacterial, parasitic, protozoal) or extra-GI causes. Consider testing for pancreatitis and infectious causes and if clinical signs persist, pursuing a fasted abdominal ultrasound. Normal thorax. Mild prostatomegaly, compatible in appearance with benign prostatic hyperplasia, less likely to represent prostatitis or prostatic neoplasia.',\n",
       "  'score': 0.951729416847229}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_model.forward(query=findings[1], k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07d0d51-5e70-4f9a-8ca7-674d48986df6",
   "metadata": {},
   "source": [
    "# Subtask breakdown\n",
    "\n",
    "The idea here is to break the task of generating the `conclusions and recommendations` from the `findings` section down into smaller more manageable tasks and then recombining. This will also allow us to investigate each component and work on addressing specific issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17b36d8b-e530-4c03-873c-9da8e3901388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "from typing import List, Dict\n",
    "import re\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1fe0656-98ba-4289-8ba7-4443d52e2369",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Finding:\n",
    "    \"\"\"Structure to hold parsed findings\"\"\"\n",
    "    anatomical_location: str\n",
    "    observation: str\n",
    "    attributes: Dict[str, str]\n",
    "\n",
    "class ExtractKeyFindings(dspy.Signature):\n",
    "    \"\"\"Extract and categorize key findings that require addressing in conclusions.\"\"\"\n",
    "    \n",
    "    finding = dspy.InputField(desc=\"Complete findings section of radiology report\")\n",
    "    similar_examples = dspy.InputField(desc=\"Similar example reports for reference\")\n",
    "    \n",
    "    abnormal_findings = dspy.OutputField(desc=\"List of abnormal findings that need to be addressed\")\n",
    "    normal_relevant = dspy.OutputField(desc=\"List of relevant normal findings that provide important context\")\n",
    "    \n",
    "class AssessClinicalSignificance(dspy.Signature):\n",
    "    \"\"\"Assess the clinical significance of the identified findings.\"\"\"\n",
    "    \n",
    "    abnormal_findings = dspy.InputField(desc=\"List of abnormal findings\")\n",
    "    normal_relevant = dspy.InputField(desc=\"List of relevant normal findings\")\n",
    "    similar_examples = dspy.InputField(desc=\"Similar example reports for reference\")\n",
    "    \n",
    "    significance = dspy.OutputField(desc=\"Clinical significance of findings\")\n",
    "    risk_assessment = dspy.OutputField(desc=\"Assessment of any risks or concerns\")\n",
    "\n",
    "class GenerateRecommendations(dspy.Signature):\n",
    "    \"\"\"Generate specific recommendations based on findings and their significance.\"\"\"\n",
    "    \n",
    "    abnormal_findings = dspy.InputField()\n",
    "    significance = dspy.InputField()\n",
    "    risk_assessment = dspy.InputField()\n",
    "    similar_examples = dspy.InputField()\n",
    "    \n",
    "    recommendations = dspy.OutputField(desc=\"Specific, actionable recommendations\")\n",
    "\n",
    "class ValidateAndFormatConclusions(dspy.Signature):\n",
    "    \"\"\"Validate and format the final conclusions section.\"\"\"\n",
    "    \n",
    "    original_finding = dspy.InputField()\n",
    "    abnormal_findings = dspy.InputField()\n",
    "    significance = dspy.InputField()\n",
    "    recommendations = dspy.InputField()\n",
    "    \n",
    "    final_conclusions = dspy.OutputField(desc=\"Complete, formatted conclusions section\")\n",
    "\n",
    "class RadiologyReportGenerator(dspy.Module):\n",
    "    \"\"\"Complete pipeline for generating radiology report conclusions.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.extract = ExtractKeyFindings()\n",
    "        self.assess = AssessClinicalSignificance()\n",
    "        self.recommend = GenerateRecommendations()\n",
    "        self.validate = ValidateAndFormatConclusions()\n",
    "        \n",
    "        # Validation rules\n",
    "        self.validation_rules = [\n",
    "            self.validate_findings_addressed,\n",
    "            self.validate_recommendation_format,\n",
    "            self.validate_medical_terminology,\n",
    "            self.validate_length,\n",
    "            self.validate_structure\n",
    "        ]\n",
    "    \n",
    "    def forward(self, finding: str, similar_examples: List[dict]) -> str:\n",
    "        # Extract key findings\n",
    "        findings_output = self.extract(\n",
    "            finding=finding,\n",
    "            similar_examples=similar_examples\n",
    "        )\n",
    "        \n",
    "        # Assess clinical significance\n",
    "        significance_output = self.assess(\n",
    "            abnormal_findings=findings_output.abnormal_findings,\n",
    "            normal_relevant=findings_output.normal_relevant,\n",
    "            similar_examples=similar_examples\n",
    "        )\n",
    "        \n",
    "        # Generate recommendations\n",
    "        recommendations = self.recommend(\n",
    "            abnormal_findings=findings_output.abnormal_findings,\n",
    "            significance=significance_output.significance,\n",
    "            risk_assessment=significance_output.risk_assessment,\n",
    "            similar_examples=similar_examples\n",
    "        )\n",
    "        \n",
    "        # Validate and format final conclusions\n",
    "        final_output = self.validate(\n",
    "            original_finding=finding,\n",
    "            abnormal_findings=findings_output.abnormal_findings,\n",
    "            significance=significance_output.significance,\n",
    "            recommendations=recommendations.recommendations\n",
    "        )\n",
    "        \n",
    "        # Run validation checks\n",
    "        self.run_validations(\n",
    "            original_finding=finding,\n",
    "            final_output=final_output.final_conclusions\n",
    "        )\n",
    "        \n",
    "        return final_output.final_conclusions\n",
    "    \n",
    "    def validate_findings_addressed(self, finding: str, conclusion: str) -> bool:\n",
    "        \"\"\"Validate that all abnormal findings are addressed in conclusions.\"\"\"\n",
    "        # Extract key medical terms from finding\n",
    "        finding_terms = self.extract_medical_terms(finding)\n",
    "        \n",
    "        # Check if key terms appear in conclusion\n",
    "        conclusion_terms = self.extract_medical_terms(conclusion)\n",
    "        \n",
    "        missing_terms = [term for term in finding_terms if term not in conclusion_terms]\n",
    "        if missing_terms:\n",
    "            raise ValidationError(f\"Findings not addressed: {missing_terms}\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def validate_recommendation_format(self, conclusion: str) -> bool:\n",
    "        \"\"\"Validate recommendation format and actionability.\"\"\"\n",
    "        # Check for specific recommendation indicators\n",
    "        recommendation_patterns = [\n",
    "            r\"recommend[s]?\\s\",\n",
    "            r\"consider[ing]?\\s\",\n",
    "            r\"warrant[s]?\\s\",\n",
    "            r\"suggest[s]?\\s\"\n",
    "        ]\n",
    "        \n",
    "        has_recommendations = any(re.search(pattern, conclusion, re.IGNORECASE) \n",
    "                                for pattern in recommendation_patterns)\n",
    "        \n",
    "        if not has_recommendations:\n",
    "            raise ValidationError(\"No clear recommendations found\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def validate_medical_terminology(self, conclusion: str) -> bool:\n",
    "        \"\"\"Validate proper use of medical terminology.\"\"\"\n",
    "        # This would connect to a medical terminology database\n",
    "        # For now, we'll use a simple check\n",
    "        required_terms = [\"examination\", \"findings\", \"indicates\", \"suggests\"]\n",
    "        \n",
    "        missing_terms = [term for term in required_terms \n",
    "                        if term.lower() not in conclusion.lower()]\n",
    "        \n",
    "        if missing_terms:\n",
    "            raise ValidationError(f\"Missing professional medical terms: {missing_terms}\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def validate_length(self, conclusion: str) -> bool:\n",
    "        \"\"\"Validate conclusion length is appropriate.\"\"\"\n",
    "        words = conclusion.split()\n",
    "        if len(words) < 50 or len(words) > 300:\n",
    "            raise ValidationError(\"Conclusion length outside acceptable range\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def validate_structure(self, conclusion: str) -> bool:\n",
    "        \"\"\"Validate conclusion structure and formatting.\"\"\"\n",
    "        required_sections = [\n",
    "            \"findings\",\n",
    "            \"significance\",\n",
    "            \"recommendations\"\n",
    "        ]\n",
    "        \n",
    "        missing_sections = [section for section in required_sections \n",
    "                          if not self._has_section(conclusion, section)]\n",
    "        \n",
    "        if missing_sections:\n",
    "            raise ValidationError(f\"Missing required sections: {missing_sections}\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def _has_section(self, text: str, section: str) -> bool:\n",
    "        \"\"\"Helper method to check if a section exists in the text.\"\"\"\n",
    "        section_patterns = [\n",
    "            f\"{section}:\",\n",
    "            f\"{section.capitalize()}:\",\n",
    "            f\"{section.upper()}:\"\n",
    "        ]\n",
    "        \n",
    "        return any(pattern in text for pattern in section_patterns)\n",
    "    \n",
    "    def extract_medical_terms(self, text: str) -> List[str]:\n",
    "        \"\"\"Extract medical terms from text.\n",
    "        This is a simplified version - in practice, you'd want to use\n",
    "        a medical NLP library or terminology database.\"\"\"\n",
    "        # Example implementation\n",
    "        terms = []\n",
    "        # Add actual medical term extraction logic\n",
    "        return terms\n",
    "    \n",
    "    def run_validations(self, original_finding: str, final_output: str):\n",
    "        \"\"\"Run all validation checks on the output.\"\"\"\n",
    "        for validation_rule in self.validation_rules:\n",
    "            if validation_rule.__name__ == 'validate_findings_addressed':\n",
    "                validation_rule(original_finding, final_output)\n",
    "            else:\n",
    "                validation_rule(final_output)\n",
    "\n",
    "class ValidationError(Exception):\n",
    "    \"\"\"Custom exception for validation errors.\"\"\"\n",
    "    pass\n",
    "\n",
    "# Example prompt templates for each component\n",
    "EXTRACT_PROMPT = \"\"\"\n",
    "Analyze the radiological findings and identify:\n",
    "1. All abnormal findings that require attention\n",
    "2. Normal findings that provide important context\n",
    "\n",
    "Format your response as two separate lists.\n",
    "Use precise medical terminology and maintain professional tone.\n",
    "\"\"\"\n",
    "\n",
    "ASSESS_PROMPT = \"\"\"\n",
    "Based on the identified findings, provide:\n",
    "1. Clinical significance of each abnormal finding\n",
    "2. Overall risk assessment considering the combination of findings\n",
    "\n",
    "Consider both immediate and potential long-term implications.\n",
    "\"\"\"\n",
    "\n",
    "RECOMMEND_PROMPT = \"\"\"\n",
    "Generate specific, actionable recommendations that:\n",
    "1. Address each significant finding\n",
    "2. Prioritize based on clinical urgency\n",
    "3. Include clear next steps for follow-up\n",
    "\n",
    "Recommendations should be concrete and specific.\n",
    "\"\"\"\n",
    "\n",
    "VALIDATE_PROMPT = \"\"\"\n",
    "Create a final conclusions section that:\n",
    "1. Integrates all components coherently\n",
    "2. Maintains professional medical tone\n",
    "3. Follows standard radiology report format\n",
    "4. Is concise and focused\n",
    "\n",
    "Ensure all significant findings are addressed and recommendations are clear.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8499e299-de0c-4f6b-8dfe-c538ae6f079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the generator\n",
    "generator = RadiologyReportGenerator()\n",
    "\n",
    "# Generate conclusions\n",
    "try:\n",
    "    conclusions = generator(finding=finding_text, similar_examples=examples)\n",
    "    print(\"Successfully generated conclusions\")\n",
    "    print(conclusions)\n",
    "except ValidationError as e:\n",
    "    print(f\"Validation failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13277c0a-95f5-4272-bfc4-46fcedf5f66f",
   "metadata": {},
   "source": [
    "## Language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4157dbf-a735-4d12-aeed-dce0b6b1a33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_model = \"qwen2.5\"\n",
    "# language_model = \"gemma2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c62e8e-3df7-466e-9621-5bcbb0c9c3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_model = dspy.OllamaLocal(\n",
    "    base_url='http://127.0.0.1:11434',\n",
    "    timeout_s=500,\n",
    "    model=language_model,\n",
    "    model_type='text',\n",
    "    max_tokens=1024,\n",
    "    num_ctx=1024,\n",
    "    temperature=0.7,\n",
    "    top_p=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d3dfda-52ca-4312-b5a6-8d014796c8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure DSPy to use Ollama\n",
    "dspy.settings.configure(lm=ollama_model, rm=retriever_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd80d22-4095-411b-9ac8-d22bc325ad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateConclusions(dspy.Signature):\n",
    "    \"\"\"Given a radiology finding and similar examples, generate an appropriate conclusions and recommendations section.\n",
    "    The response should maintain a professional medical tone and follow the style of the examples.\"\"\"\n",
    "\n",
    "    finding = dspy.InputField(desc=\"Findings section of the radiology report.\")\n",
    "    similar_examples = dspy.InputField(desc=\"Similar examples of findings and corresponding conclusions and recommendations sections.\")\n",
    "    conclusions = dspy.OutputField(desc=\"The conclusions and recommendations section. Give the findings section above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92488ee-81ba-4e39-a514-9faa83ee234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RadiologyModule(dspy.Module):\n",
    "    def __init__(self, retriever):\n",
    "        super().__init__()\n",
    "        self.generate_conclusion = dspy.Predict(GenerateConclusions)\n",
    "        self.retriever = retriever\n",
    "\n",
    "    def forward(self, finding: str) -> dict:\n",
    "        # Retrieve similar examples\n",
    "        retrieved = self.retriever(finding, k=3)\n",
    "        \n",
    "        # Format examples for prompt\n",
    "        examples_text = \"\"\n",
    "        for i, ex in enumerate(retrieved, 1):\n",
    "            examples_text += f\"Example {i}:\\n\"\n",
    "            examples_text += f\"Finding: {ex['finding']}\\n\"\n",
    "            examples_text += f\"Conclusion: {ex['conclusion']}\\n\\n\"\n",
    "\n",
    "        # Generate new conclusion\n",
    "        prediction = self.generate_conclusion(\n",
    "            finding=finding,\n",
    "            similar_examples=examples_text\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'finding': finding,\n",
    "            'generated_conclusion': prediction.conclusions,\n",
    "            'similar_examples': retrieved\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab50c82-0b84-4ca6-bb49-beec9c71f26b",
   "metadata": {},
   "source": [
    "## Full pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8060bf-a509-4bba-932f-d8b1526bd1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_rad_pipeline(filepath: str, vectorizer: str = \"sentence-transformers/all-MiniLM-L6-v2\", k: int = 3):\n",
    "    \"\"\"\n",
    "    Set up the complete radiology report generation pipeline\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    df = json_to_dataframe(filepath)\n",
    "    findings = list(df['findings'])\n",
    "    conclusions = list(df['conclusions_and_recommendations'])\n",
    "    \n",
    "    # Initialize retriever\n",
    "    retriever = SentenceTransformerRetriever(\n",
    "        model=vectorizer,\n",
    "        findings=findings,\n",
    "        conclusions=conclusions,\n",
    "        k=k\n",
    "    )\n",
    "    \n",
    "    # Create and return the radiology module\n",
    "    return RadiologyModule(retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff638ac-cba8-48c5-9dcd-7b09ea02962d",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a094450-dd96-4a65-a258-2a18682e09bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '../../data/vector_veterinary_imaging_2.json'\n",
    "rad_pipeline = setup_rad_pipeline(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a23e4e-2355-44dc-b1ee-4648e55f1ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example finding\n",
    "test_finding = \"\"\"\n",
    "The thoracic cavity demonstrates normal cardiac silhouette size and shape. \n",
    "The pulmonary vasculature appears within normal limits. \n",
    "There is a mild interstitial pattern noted in the caudodorsal lung fields.\n",
    "No evidence of pleural effusion is noted.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4301a2ff-6e89-4fe9-9e31-2798d819c5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = rad_pipeline(test_finding)\n",
    "    \n",
    "print(\"Generated Conclusion:\")\n",
    "print(result['generated_conclusion'])\n",
    "print(\"\\nSimilar Examples Used:\")\n",
    "for i, example in enumerate(result['similar_examples'], 1):\n",
    "    print(f\"\\nExample {i} (Similarity Score: {example['score']:.3f}):\")\n",
    "    print(f\"Finding: {example['finding']}\")\n",
    "    print(f\"Conclusion: {example['conclusion']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da984fd5-2079-48fc-8991-fc91428a3c15",
   "metadata": {},
   "source": [
    "## Remove the example in question from retrieval\n",
    "\n",
    "As we go through a handful of examples, we want to make sure we don't include the example itself in the retrieval set. But it is fine to include all other examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7aa8fc-9d28-4351-9336-f4848b6b2639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import List, Dict, Union, Optional\n",
    "import pandas as pd\n",
    "\n",
    "class SentenceTransformerRetrieverWithExclusion(dspy.Retrieve):\n",
    "    def __init__(self, model: str, findings: List[str], conclusions: List[str], k: int):\n",
    "        self.model = model if isinstance(model, SentenceTransformer) else SentenceTransformer(model, trust_remote_code=True)\n",
    "        self.findings = findings\n",
    "        self.conclusions = conclusions\n",
    "        self.k = k\n",
    "        self.embeddings = None\n",
    "        self.excluded_indices = set()\n",
    "        self.init_embeddings()\n",
    "\n",
    "    def init_embeddings(self):\n",
    "        self.embeddings = self.model.encode(self.findings)\n",
    "        \n",
    "    def set_excluded_indices(self, indices: Optional[List[int]] = None):\n",
    "        \"\"\"Set indices to exclude from retrieval\"\"\"\n",
    "        self.excluded_indices = set(indices or [])\n",
    "        \n",
    "    def clear_excluded_indices(self):\n",
    "        \"\"\"Clear all excluded indices\"\"\"\n",
    "        self.excluded_indices = set()\n",
    "\n",
    "    def forward(self, query: str, k: int) -> List[Dict[str, Union[str, float]]]:\n",
    "        query_embedding = self.model.encode([query])\n",
    "        similarities = cosine_similarity(query_embedding, self.embeddings)[0]\n",
    "        \n",
    "        # Create mask for excluded indices\n",
    "        mask = np.ones_like(similarities, dtype=bool)\n",
    "        if self.excluded_indices:\n",
    "            mask[list(self.excluded_indices)] = False\n",
    "        \n",
    "        # Get top k indices excluding masked indices\n",
    "        masked_similarities = similarities.copy()\n",
    "        masked_similarities[~mask] = -np.inf\n",
    "        top_k_indices = np.argsort(masked_similarities)[-k:][::-1]\n",
    "\n",
    "        results = []\n",
    "        for idx in top_k_indices:\n",
    "            results.append({\n",
    "                'finding': self.findings[idx],\n",
    "                'conclusion': self.conclusions[idx],\n",
    "                'score': float(similarities[idx])\n",
    "            })\n",
    "\n",
    "        return results\n",
    "\n",
    "def setup_rad_pipeline_with_exclusion(filepath: str, vectorizer: str = \"sentence-transformers/all-MiniLM-L6-v2\", k: int = 3):\n",
    "    \"\"\"\n",
    "    Set up the radiology pipeline with exclusion capability\n",
    "    \"\"\"\n",
    "    df = json_to_dataframe(filepath)\n",
    "    findings = list(df['findings'])\n",
    "    conclusions = list(df['conclusions_and_recommendations'])\n",
    "    \n",
    "    retriever = SentenceTransformerRetrieverWithExclusion(\n",
    "        model=vectorizer,\n",
    "        findings=findings,\n",
    "        conclusions=conclusions,\n",
    "        k=k\n",
    "    )\n",
    "    \n",
    "    return RadiologyModule(retriever), df\n",
    "\n",
    "def run_evaluation_with_exclusion(filepath: str, num_examples: int = 5, seed: Optional[int] = None):\n",
    "    \"\"\"\n",
    "    Run inference on a specified number of examples, excluding each example from its own retrieval set\n",
    "    \n",
    "    Args:\n",
    "        filepath: Path to the JSON data file\n",
    "        num_examples: Number of examples to evaluate\n",
    "        seed: Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame containing the evaluation results\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "        \n",
    "    # Setup pipeline with exclusion capability\n",
    "    rad_pipeline, df = setup_rad_pipeline_with_exclusion(filepath)\n",
    "    \n",
    "    # Randomly select examples\n",
    "    total_examples = len(df)\n",
    "    selected_indices = random.sample(range(total_examples), min(num_examples, total_examples))\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for idx in selected_indices:\n",
    "        # Get the example\n",
    "        finding = df['findings'].iloc[idx]\n",
    "        actual_conclusion = df['conclusions_and_recommendations'].iloc[idx]\n",
    "        \n",
    "        # Set the current example to be excluded from retrieval\n",
    "        rad_pipeline.retriever.set_excluded_indices([idx])\n",
    "        \n",
    "        # Run inference\n",
    "        result = rad_pipeline(finding)\n",
    "        \n",
    "        # Clear exclusion for next iteration\n",
    "        rad_pipeline.retriever.clear_excluded_indices()\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            'index': idx,\n",
    "            'finding': finding,\n",
    "            'actual_conclusion': actual_conclusion,\n",
    "            'generated_conclusion': result['generated_conclusion'],\n",
    "            'similar_examples': result['similar_examples']\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a62efbf-ed5a-4bb7-95df-3f9d3a8f63d2",
   "metadata": {},
   "source": [
    "## TODO \n",
    "\n",
    "Pull out a handful of examples of prompts, actual conclusions, and predicted conclusions and have the model judge how close the actual and predicted responses are and also to come up with a new set of prompts that might work better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6aa078-9177-44bf-bb81-00f4c716648e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '../../data/vector_veterinary_imaging_2.json'\n",
    "\n",
    "# Run evaluation on 3 random examples\n",
    "results_df = run_evaluation_with_exclusion(filepath, num_examples=3, seed=42)\n",
    "\n",
    "# Print results\n",
    "for idx, row in results_df.iterrows():\n",
    "    print(f\"\\nExample {idx + 1}:\")\n",
    "    print(\"Finding:\")\n",
    "    print(row['finding'])\n",
    "    print(\"\\nActual Conclusion:\")\n",
    "    print(row['actual_conclusion'])\n",
    "    print(\"\\nGenerated Conclusion:\")\n",
    "    print(row['generated_conclusion'])\n",
    "    print(\"\\nSimilar Examples Used:\")\n",
    "    for i, example in enumerate(row['similar_examples'], 1):\n",
    "        print(f\"\\nReference {i} (Similarity Score: {example['score']:.3f}):\")\n",
    "        print(f\"Finding: {example['finding']}\")\n",
    "        print(f\"Conclusion: {example['conclusion']}\")\n",
    "    print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4e7ef3-ad07-44db-9a69-ccfd8ed941e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2092d672-a4c2-4a51-9ae4-5d84ca27634f",
   "metadata": {},
   "source": [
    "## TODO \n",
    "\n",
    "incorporate the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3506126-96d9-4c42-a7a6-54f1cb82e33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_evaluation_results(results_df: pd.DataFrame, output_path: str, format: str = 'json'):\n",
    "    \"\"\"\n",
    "    Save evaluation results for LLM analysis\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame containing evaluation results\n",
    "        output_path: Path to save the results\n",
    "        format: Either 'json' or 'csv'\n",
    "    \"\"\"\n",
    "    # Prepare data for export\n",
    "    export_data = []\n",
    "    for _, row in results_df.iterrows():\n",
    "        export_row = {\n",
    "            'finding': row['finding'],\n",
    "            'actual_conclusion': row['actual_conclusion'],\n",
    "            'generated_conclusion': row['generated_conclusion'],\n",
    "            'reference_examples': [\n",
    "                {\n",
    "                    'finding': ex['finding'],\n",
    "                    'conclusion': ex['conclusion'],\n",
    "                    'similarity_score': float(ex['score'])\n",
    "                } for ex in row['similar_examples']\n",
    "            ]\n",
    "        }\n",
    "        export_data.append(export_row)\n",
    "    \n",
    "    # Save in specified format\n",
    "    if format.lower() == 'json':\n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(export_data, f, indent=2)\n",
    "    else:  # csv\n",
    "        # Flatten the reference examples\n",
    "        flat_data = []\n",
    "        for item in export_data:\n",
    "            flat_item = {\n",
    "                'finding': item['finding'],\n",
    "                'actual_conclusion': item['actual_conclusion'],\n",
    "                'generated_conclusion': item['generated_conclusion']\n",
    "            }\n",
    "            for i, ref in enumerate(item['reference_examples'], 1):\n",
    "                flat_item[f'ref_{i}_finding'] = ref['finding']\n",
    "                flat_item[f'ref_{i}_conclusion'] = ref['conclusion']\n",
    "                flat_item[f'ref_{i}_similarity'] = ref['similarity_score']\n",
    "            flat_data.append(flat_item)\n",
    "        pd.DataFrame(flat_data).to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e58bab1-eb66-45f2-b3c6-4bb72b19252d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '../../data/vector_veterinary_imaging_2.json'\n",
    "    \n",
    "# Run evaluation and save results\n",
    "results_df = run_evaluation_with_exclusion(filepath, num_examples=20, seed=42)\n",
    "save_evaluation_results(results_df, 'evaluation_results.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120cbe26-82ab-43ec-9f38-dbdfb8ca9a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56caaf3-f00f-46ea-94ca-beef5be20462",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List, Dict, Union\n",
    "import pandas as pd\n",
    "import dspy\n",
    "from dspy.teleprompt import BootstrapFewShot, ValueEstimator\n",
    "import numpy as np\n",
    "\n",
    "class ConclusionScorer(dspy.Signature):\n",
    "    \"\"\"Rate the quality and accuracy of generated radiology conclusions compared to actual conclusions.\"\"\"\n",
    "    \n",
    "    finding = dspy.InputField()\n",
    "    generated_conclusion = dspy.InputField()\n",
    "    actual_conclusion = dspy.InputField()\n",
    "    \n",
    "    score = dspy.OutputField(desc=\"Score from 0-1 indicating similarity of content and style\")\n",
    "    reasoning = dspy.OutputField(desc=\"Explanation of the score and suggestions for improvement\")\n",
    "\n",
    "class RadiologyValueEstimator(ValueEstimator):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.scorer = dspy.Predict(ConclusionScorer)\n",
    "    \n",
    "    def forward(self, example, pred, trace=None):\n",
    "        score = self.scorer(\n",
    "            finding=example.finding,\n",
    "            generated_conclusion=pred.conclusions,\n",
    "            actual_conclusion=example.actual_conclusion\n",
    "        )\n",
    "        return float(score.score)\n",
    "\n",
    "def optimize_rad_prompt(filepath: str, num_bootstrap_examples: int = 10):\n",
    "    \"\"\"\n",
    "    Use DSPy's teleprompter to optimize the radiology prompt\n",
    "    \n",
    "    Args:\n",
    "        filepath: Path to the dataset\n",
    "        num_bootstrap_examples: Number of examples to use for bootstrapping\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    df = json_to_dataframe(filepath)\n",
    "    \n",
    "    # Prepare training data\n",
    "    train_data = [\n",
    "        dspy.Example(\n",
    "            finding=row['findings'],\n",
    "            actual_conclusion=row['conclusions_and_recommendations']\n",
    "        ).with_inputs('finding')\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "    \n",
    "    # Initialize teleprompter components\n",
    "    bootstrapper = BootstrapFewShot(\n",
    "        demo_retriever='bm25',  # or 'sbert' for semantic search\n",
    "        k=num_bootstrap_examples\n",
    "    )\n",
    "    \n",
    "    value_estimator = RadiologyValueEstimator()\n",
    "    \n",
    "    # Create compiler configuration\n",
    "    config = dspy.TelepromptConfig(\n",
    "        metric=value_estimator,\n",
    "        max_bootstrapping_iterations=3,\n",
    "        max_rounds=5\n",
    "    )\n",
    "    \n",
    "    # Initialize and run teleprompter\n",
    "    teleprompter = dspy.Teleprompter(\n",
    "        GenerateConclusions,\n",
    "        bootstrapper=bootstrapper,\n",
    "        config=config\n",
    "    )\n",
    "    \n",
    "    # Optimize the prompt\n",
    "    optimized_program = teleprompter.compile(\n",
    "        train_data=train_data,\n",
    "        eval_data=train_data[:100]  # Use subset for evaluation\n",
    "    )\n",
    "    \n",
    "    return optimized_program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8ee13a-c48e-4030-bcb6-db11392e091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    filepath = '../../data/vector_veterinary_imaging_2.json'\n",
    "    \n",
    "    # Run evaluation and save results\n",
    "    results_df = run_evaluation_with_exclusion(filepath, num_examples=20, seed=42)\n",
    "    save_evaluation_results(results_df, 'evaluation_results.json')\n",
    "    \n",
    "    # Optimize prompt using teleprompter\n",
    "    optimized_program = optimize_rad_prompt(filepath)\n",
    "    \n",
    "    # Print optimized prompt\n",
    "    print(\"Optimized Prompt:\")\n",
    "    print(optimized_program.signature.instructions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
