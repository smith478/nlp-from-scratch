{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23037aab-769a-467c-b4c6-a689d3ab51ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38145ed6-c229-424f-a20b-b224be98667a",
   "metadata": {},
   "source": [
    "## Define dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e4fa00-662c-44e3-9da1-62fc80ddae09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_and_decode_example(list_of_strings):\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Get the token ID for <|endoftext|>\n",
    "    endoftext_token = tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"})[0]\n",
    "\n",
    "    all_tokens = []\n",
    "    for text in list_of_strings:\n",
    "        # Encode the text\n",
    "        encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "        all_tokens.extend(encoded + [endoftext_token])\n",
    "\n",
    "    # Decode the tokens\n",
    "    decoded = tokenizer.decode(all_tokens)\n",
    "\n",
    "    return all_tokens, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a53cb81-7240-4cfd-9d45-dc3aa0fbe53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, articles, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Get the token ID for <|endoftext|>\n",
    "        endoftext_token = tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"})[0]\n",
    "\n",
    "        # Tokenize all articles with end-of-text token\n",
    "        all_tokens = []\n",
    "        for article in articles:\n",
    "            article_tokens = tokenizer.encode(article, allowed_special={\"<|endoftext|>\"})\n",
    "            all_tokens.extend(article_tokens + [endoftext_token])\n",
    "\n",
    "        # Use a sliding window to chunk the tokens into overlapping sequences of max_length\n",
    "        for i in range(0, len(all_tokens) - max_length, stride):\n",
    "            input_chunk = all_tokens[i:i + max_length]\n",
    "            target_chunk = all_tokens[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3796d3da-d0c2-48e9-b141-da4277d40833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(articles, batch_size=4, max_length=256, \n",
    "                         stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(articles, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7e2d9a-fbbc-47b7-a8ee-efc5117dcfca",
   "metadata": {},
   "source": [
    "## Load Reuters dataset\n",
    "\n",
    "#### TODO\n",
    "- Deduplicate articles so that there is 1 per ID, not 1 per topic\n",
    "- Load all the articles, not just the single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0defca-03d3-4a10-ba91-f027bb2e7f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = parse_sgm_to_dataframe('../data/reuters21578/reut2-000.sgm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82be9a4a-ec82-48c6-9bec-16c4ff640654",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = list(df['Body'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2db3b1-0211-40d0-8d01-fe9d9c555f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28363559-3f43-4eda-9105-d41e1fdc8acb",
   "metadata": {},
   "source": [
    "## Create data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738db129-e6c7-4682-9a14-6be51c9076c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "max_len = 1024\n",
    "context_length = max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e6bb14-7b1e-429d-b728-0e6115451c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "token_embedding_layer = nn.Embedding(vocab_size, output_dim)\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc49c66-779f-4194-a21c-a9c838652d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(articles, batch_size=8, max_length=max_length, stride=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d0c24a-88b4-4e52-b989-478c666685d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_batch(x, y, n_samples=2):\n",
    "    for i in range(min(n_samples, len(x))):\n",
    "        tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "        \n",
    "        print(f\"\\nSample {i+1}:\")\n",
    "        \n",
    "        # Decode and print the input sequence\n",
    "        input_text = tokenizer.decode(x[i].tolist())\n",
    "        print(f\"Input text: {input_text}\")\n",
    "        print(f\"Input encoding: {x[i].tolist()}\")\n",
    "        \n",
    "        # Decode and print the target sequence\n",
    "        target_text = tokenizer.decode(y[i].tolist())\n",
    "        print(f\"Target text: {target_text}\")\n",
    "        print(f\"Target encoding: {y[i].tolist()}\")\n",
    "        \n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e2634e-79b0-4bab-b53b-3d6aa9c584d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSPECT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a84c4a1-cfbd-4b73-a397-2a7f2929e8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataloader:\n",
    "    x, y = batch\n",
    "\n",
    "    if INSPECT:\n",
    "        # Visual inspection\n",
    "        inspect_batch(x, y)\n",
    "\n",
    "    token_embeddings = token_embedding_layer(x)\n",
    "    pos_embeddings = pos_embedding_layer(torch.arange(max_length))\n",
    "\n",
    "    input_embeddings = token_embeddings + pos_embeddings\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6d1d95-18b8-4c2f-85b9-4617dfc2c260",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_embeddings.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
