{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73836c4a-12db-4f86-9310-09374621d3f2",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation - RAG \n",
    "\n",
    "We will use the RAG technique to use language models to attempt to solve the multi-class, multi-label classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3abf0e8-8692-488f-a941-820ec6da5269",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.retrieve.qdrant_rm import QdrantRM\n",
    "from qdrant_client import QdrantClient\n",
    "import dspy\n",
    "import json\n",
    "from typing import List, Dict, Tuple\n",
    "from utils import parse_sgm_to_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2d6b02-8f86-45c8-ac13-525484a6a2d2",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b65e32-f40c-4cd8-af48-170bf44de1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = parse_sgm_to_dataframe('../../data/reuters21578/reut2-000.sgm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38adab50-2e10-4462-abd6-315214216f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_topics_in_file(topic_list, file_path):\n",
    "    # Read topics from the file\n",
    "    with open(file_path, 'r') as file:\n",
    "        file_topics = set(file.read().splitlines())\n",
    "    \n",
    "    # Check if all topics in topic_list are in file_topics\n",
    "    missing_topics = set(topic_list) - file_topics\n",
    "    \n",
    "    if not missing_topics:\n",
    "        return True, []\n",
    "    else:\n",
    "        return False, list(missing_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f5320e-199f-4dc4-8b9c-cf20b72ace15",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_list = df['Topic'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e93855-fd4e-4aec-82ea-07e6ae12131f",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_list = [topic for topic in topic_list if topic != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca2a85f-bcaf-4d9a-92b7-fea744347a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_topics_in_file(topic_list, '../../data/reuters21578/all-topics-strings.lc.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7b96ee-2639-488f-9892-8b6667d3eaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_file = '../../data/reuters21578/all-topics-strings.lc.txt'\n",
    "with open(topic_file, 'r') as file:\n",
    "    file_topics = set(file.read().splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0baca1b-902c-4396-a102-427482634609",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = list(file_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502e62b4-f078-4892-a330-5a5431f6dacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [s.strip() for s in topics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c1edb4-8488-4b1f-8c48-079a3ab5ac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f752d3-8e40-4c83-ae7f-a1d2d14a8af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ac7156-9788-4a14-84ef-3d313000c2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeee974e-9a61-4ad9-9f70-46b93728e586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_reuters_dataframe(df):\n",
    "    # Initialize a dictionary to store bodies and topics\n",
    "    articles = {}\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        article_id = row['ID']\n",
    "        body = row['Body']\n",
    "        topic = row['Topic']\n",
    "        \n",
    "        # If the article_id is not yet in the dictionary, add it\n",
    "        if article_id not in articles:\n",
    "            articles[article_id] = {'body': body, 'topics': []}\n",
    "        \n",
    "        # Append the topic to the list of topics if it's not blank\n",
    "        if pd.notna(topic) and topic.strip() != \"\":\n",
    "            articles[article_id]['topics'].append(topic)\n",
    "    \n",
    "    # Convert the dictionary to two lists\n",
    "    bodies = [data['body'] for data in articles.values()]\n",
    "    topics = [data['topics'] for data in articles.values()]\n",
    "    \n",
    "    return bodies, topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c063507d-ed63-4aac-a2bc-83b24462d645",
   "metadata": {},
   "outputs": [],
   "source": [
    "bodies, topics = parse_reuters_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07283950-9c3e-4dbb-b37a-5ac36c9671d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bodies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a71ffa7-5026-4b06-afe0-0634d33d4dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e36df9a-6ad9-45d9-a88a-514c905e2e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d6205f-2fed-4cf8-b586-79fcf90bc863",
   "metadata": {},
   "outputs": [],
   "source": [
    "bodies[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08350ad8-769d-4245-a76f-423209c53869",
   "metadata": {},
   "source": [
    "## Find suitable pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13badf4e-548f-42c9-9dc8-c88b28dbc4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7c66d3-ecd3-4642-bdde-af74306d1fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_json_string(json_str: str) -> str:\n",
    "    # Remove the backticks and the \"json\" text\n",
    "    return json_str.replace('```json\\n', '').replace('\\n```', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f070bbe3-7a51-44f2-8eca-04bd57bf4a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_sentences(text):\n",
    "    # This regex splits sentences but ignores periods in common abbreviations\n",
    "    pattern = r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!)\\s'\n",
    "    sentences = re.split(pattern, text)\n",
    "    return [s.strip() for s in sentences if s.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aee9c3-3664-416b-9d7a-4d04c4775a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_ollama_output(output_str: str, clean_values: bool = True) -> List[str]:\n",
    "    if clean_values:\n",
    "        output_str = clean_json_string(output_str)\n",
    "    output_dict = json.loads(output_str)\n",
    "    predicted_classes = [key for key, value in output_dict.items() if value == 1]\n",
    "    return predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed21fe3a-083f-47b0-b756-1178b5d5f1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_retriever_client(labels: List[str], collection_name: str, k: int, vectorizer: str = None) -> QdrantRM:\n",
    "    client = QdrantClient(\":memory:\")\n",
    "    ids = list(range(len(labels)))\n",
    "    \n",
    "    if vectorizer:\n",
    "        client.set_model(vectorizer)\n",
    "        \n",
    "    client.add(\n",
    "        collection_name=collection_name,\n",
    "        documents=labels,\n",
    "        ids=ids\n",
    "    )\n",
    "    return QdrantRM(collection_name, client, k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf33db70-11d3-4483-b646-f9f861ee3756",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifyText(dspy.Signature):\n",
    "    \"\"\"Classify the news article into multiple topic labels from the given candidates. \n",
    "    It is possible to have no label, a single label, or multiple labels. You should return the \n",
    "    extracted information as a single JSON string with a key for each candidate topic label and a value of\n",
    "    1 if the article is about the topic and 0 otherwise. There should be no\n",
    "    text or explanation, only the JSON. For example if there \n",
    "    were 3 candidates you could have the following output:\n",
    "\n",
    "    {\n",
    "        \"label_1\": 1,\n",
    "        \"label_2\": 0,\n",
    "        \"label_3\": 1\n",
    "    }\"\"\"\n",
    "    text = dspy.InputField()\n",
    "    label_candidates = dspy.InputField(desc=\"List of candidate labels for the text\")\n",
    "    article_labels = dspy.OutputField(desc=\"Dictionary of candidate labels, 1 or 0, for the text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de341f02-36f0-4c2e-b7e3-2ca3f7ceb667",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGMultiLabelClassifier(dspy.Module):\n",
    "    def __init__(self, custom_retriever, num_candidates=10):\n",
    "        super().__init__()\n",
    "        self.retrieve = custom_retriever\n",
    "        self.classify = dspy.Predict(ClassifyText)\n",
    "        self.num_candidates = num_candidates\n",
    "    \n",
    "    def forward(self, text):\n",
    "        sentences = split_sentences(text)\n",
    "        all_retrieved_labels = set()\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            retrieved_docs = self.retrieve(sentence, k=self.num_candidates)\n",
    "            sentence_labels = [doc['long_text'] for doc in retrieved_docs]\n",
    "            all_retrieved_labels.update(sentence_labels)\n",
    "        \n",
    "        retrieved_labels = ','.join(all_retrieved_labels)\n",
    "        print(f\"Retrieved labels: {retrieved_labels}\")\n",
    "        \n",
    "        classification_result = self.classify(text=text, label_candidates=retrieved_labels)\n",
    "        result = classification_result.article_labels\n",
    "        result = clean_json_string(result)\n",
    "        \n",
    "        logger.debug(f\"Raw classification result: {result}\")\n",
    "        \n",
    "        try:\n",
    "            parsed_result = json.loads(result)\n",
    "        except json.JSONDecodeError:\n",
    "            # If JSON parsing fails, try to extract a dictionary-like structure\n",
    "            import re\n",
    "            dict_match = re.search(r'\\{.*\\}', result, re.DOTALL)\n",
    "            if dict_match:\n",
    "                dict_str = dict_match.group(0)\n",
    "                try:\n",
    "                    parsed_result = eval(dict_str)\n",
    "                except:\n",
    "                    parsed_result = {\"wrong\": 1}  # Fallback to hard-coded wrong output\n",
    "            else:\n",
    "                parsed_result = {\"wrong\": 1}  # Fallback to hard-coded wrong output\n",
    "        \n",
    "        # Ensure the output is a dictionary\n",
    "        if not isinstance(parsed_result, dict):\n",
    "            parsed_result = {\"wrong\": 1}  # Fallback to hard-coded wrong output\n",
    "        \n",
    "        logger.debug(f\"Final parsed result: {parsed_result}\")\n",
    "        return parsed_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c09167-a481-4fd3-9b49-4ccc5a80d9d6",
   "metadata": {},
   "source": [
    "## Explore the use of models pretrained on article data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af24155d-4a93-4f74-8716-7e2a05a4e7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = \"BAAI/bge-large-en-v1.5\"\n",
    "ollama_model_name = 'gemma2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b5435c-c5db-4c97-8c56-97d593b98563",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_model = build_retriever_client(labels=topic_list, \n",
    "                                         collection_name=\"reuters\", \n",
    "                                         k=10, \n",
    "                                         vectorizer=vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6539d97f-5faf-468a-ae00-227ce3861bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOllamaLocal(dspy.OllamaLocal):\n",
    "    def __init__(self, model, **kwargs):\n",
    "        logger.debug(f\"Initializing CustomOllamaLocal with model: {model}\")\n",
    "        self.model = model  # Explicitly set the model attribute\n",
    "        super().__init__(model=model, **kwargs)\n",
    "        \n",
    "    def copy(self, **kwargs):\n",
    "        logger.debug(f\"Copying CustomOllamaLocal with kwargs: {kwargs}\")\n",
    "        new_kwargs = self.__dict__.copy()\n",
    "        new_kwargs.update(kwargs)\n",
    "        return CustomOllamaLocal(**new_kwargs)\n",
    "    \n",
    "    def basic_request(self, prompt, **kwargs):\n",
    "        logger.debug(f\"Making basic request with model: {self.model}\")\n",
    "        return super().basic_request(prompt, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1d16bb-ce07-4b18-8bcf-a470d44b6e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_model = CustomOllamaLocal(\n",
    "    model=ollama_model_name, \n",
    "    model_type='text',\n",
    "    max_tokens=512,\n",
    "    temperature=0,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    top_k=10,\n",
    "    format='json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66126aab-5e3d-4d00-bbc9-15b1efe1eba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy.settings.configure(lm=ollama_model, rm=retriever_model)\n",
    "classifier = RAGMultiLabelClassifier(custom_retriever=retriever_model, num_candidates=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5590a0-aabd-4193-9540-aafd9cd3fe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(ground_truth: List[List[str]], predictions: List[List[str]]) -> Dict[str, float]:\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "\n",
    "    for gt_labels, pred_labels in zip(ground_truth, predictions):\n",
    "        gt_set = set(gt_labels)\n",
    "        pred_set = set(pred_labels)\n",
    "\n",
    "        tp += len(gt_set & pred_set)\n",
    "        fp += len(pred_set - gt_set)\n",
    "        fn += len(gt_set - pred_set)\n",
    "\n",
    "    precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "    recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "\n",
    "    return {\"precision\": precision, \"recall\": recall, \"f1_score\": f1_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e4ea3d-fdf1-4268-ae89-b762e90a7b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def sample_bodies_and_topics(bodies, topics, num_samples, random_seed=None):\n",
    "    # Ensure the length of bodies and topics are the same\n",
    "    assert len(bodies) == len(topics), \"Bodies and topics lists must be of the same length.\"\n",
    "    \n",
    "    # Set the random seed if provided\n",
    "    if random_seed is not None:\n",
    "        random.seed(random_seed)\n",
    "    \n",
    "    # Create a list of indices and sample from them\n",
    "    indices = list(range(len(bodies)))\n",
    "    sampled_indices = random.sample(indices, num_samples)\n",
    "    \n",
    "    # Create the sampled lists for bodies and topics\n",
    "    sampled_bodies = [bodies[i] for i in sampled_indices]\n",
    "    sampled_topics = [topics[i] for i in sampled_indices]\n",
    "    \n",
    "    return sampled_bodies, sampled_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02ab0ea-cf89-433f-b8de-68e44ea66bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bodies, topics = sample_bodies_and_topics(bodies, topics, num_samples=10, random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3a6230-b086-43b1-81bc-54ada5145a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "raw_results = []\n",
    "\n",
    "for i, (topic, body) in enumerate(zip(topics, bodies)):\n",
    "    result_str = classifier(text=body)\n",
    "    try:\n",
    "        if isinstance(result_str, str):\n",
    "            predicted_classes = parse_ollama_output(result_str)\n",
    "        else:\n",
    "            predicted_classes = [k for k, v in result_str.items() if v == 1]\n",
    "        predictions.append(predicted_classes)\n",
    "\n",
    "        raw_results.append({\n",
    "            'body': body,\n",
    "            'predicted_labels': json.dumps(predicted_classes),\n",
    "            'actual_labels': json.dumps(topic)\n",
    "        })\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Warning! Could not parse output from Ollama. Skipping this result.\")\n",
    "        print(f'Body: {body}')\n",
    "        print(f'Result string: {result_str}')\n",
    "        continue\n",
    "\n",
    "metrics = calculate_metrics(bodies, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c020182-2783-4969-bb28-ea8cd6d9bd6a",
   "metadata": {},
   "source": [
    "## Optimize our RAG pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a4f2f9-c47e-4a1b-be95-83e937ebc075",
   "metadata": {},
   "source": [
    "## Explore retrieval improvements\n",
    "\n",
    "Retrieval is in-expensive so it is in most cases a good tradeoff to do more on the retrieval side in order to ensure that we have a good list of candidate labels that includes the true labels.\n",
    "\n",
    "To explore:\n",
    "- Sentence splitting\n",
    "- Retrieval ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e2fd2c-2b38-4c43-ba9c-af2acb50247a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
